{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c17f69-351a-4106-bba7-7a2aecf25d83",
   "metadata": {},
   "source": [
    "# Project: Ham vs. Spam (Text Classification)\n",
    "\n",
    "## Overview\n",
    "In this project you will build a machine learning model that predicts whether a text message is **ham** (normal) or **spam** (unwanted/advertising/scam). This is one of the most common “real world” classification problems and is a great way to practice the full data science workflow.\n",
    "\n",
    "You will work with a labeled dataset of SMS messages and train a model using features created from text (for example: **bag-of-words** or **TF–IDF**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f319894c-3075-48cf-8aeb-e65bf2ca85fc",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "- Utilizing the two baseline models, I performed several tests on text vectorization transformer using 5-fold cross validation on the training set. \n",
    "    - Enabling bi- and tri-grams using n_grams provided a minor improvement on precision. Precision improved from 0.918 to 0.94 - slightly better than 0.5-sigma.\n",
    "    - TF-IDF vectorization performed slightly worse on decision tree and significantly worse on logistic regression. Enabling stop_words on TF-IDF further degraded performance.\n",
    "    - As a negative control, I disabled stop words and found that decision tree performed slightly worse but logistic regression slightly improved - both well less than 1-sigma of effect. Going a step further, removing the text cleaning and reverting to the original text column lead to improvement on the logistic regression of 0.7-sigma. This is surprising and if I had to guess, is due to the sloppy mix of vernacular, shorthand, and typos in the corpus and I do not think this would lead to improvement in other datasets.\n",
    "    - Utilizing n_grams does not trigger any new entries in the top 50 word lists (corpus nor spam), but n_grams have appeared in the top features for our baseline models: free sms, free wan help, just text, fraction cost reply, new message, message waiting, place send free\n",
    "\n",
    "<p style=\"text-align:center;\"><b>Precision CV (mean +/- stdev)</b></p>\n",
    "\n",
    "| Vectorization Strategy | Decision Tree (20) | Logistic Regression (0.5, balanced) |\n",
    "| ---------------------- | :----------------: | :---------------------------------: |\n",
    "| Baseline               | 0.918 +/- 0.028    | 0.925 +/- 0.034                     |\n",
    "| n_grams(1,2)           | 0.939 +/- 0.026    | 0.940 +/- 0.034                     |\n",
    "| **n_grams(1,3)**       | 0.940 +/- 0.021    | 0.945 +/- 0.033                     |\n",
    "| TF-IDF (w/o stop words)| 0.903 +/- 0.019    | 0.805 +/- 0.036                     |\n",
    "| TF-IDF (w/  stop words)| 0.900 +/- 0.025    | 0.758 +/- 0.036                     |\n",
    "| Disable Stopwords      | 0.907 +/- 0.012    | 0.931 +/- 0.029                     |\n",
    "| Skip Text Cleaning     | 0.915 +/- 0.017    | 0.948 +/- 0.024                     |\n",
    "\n",
    "- After incorporating tri-grams into my standard pipeline, I selected several ensemble methods representing both bagging and boosting strategies.\n",
    "    - Random Forest performed perfectly for precision, but was among one of the worst performers for recall.\n",
    "    - K-nearest neighbors had the 2nd best score for precision, but was unacceptably bad for recall.\n",
    "    - Gradient Boosting and XGBoost both performed well. Without optimization, gradient boost outperformed on precision at the expense of recall, while XGBoost was more balanced between the two scores.\n",
    "    - I did a quick round of hyperparameter tuning on the top two models but could not significantly improve either model.\n",
    "\n",
    "\n",
    " | Model Args           | Precision | Recall | F1 Score | Accuracy | Train - F1 Score |\n",
    " | -------------------- | :-------: | :----: | :------: | :------: | :--------------: |\n",
    " | AdaBoostClassifier   | 0.948 +/- 0.017 | 0.856 +/- 0.027 | 0.899 +/- 0.019 | 0.974 +/- 0.005 | 1.000 +/- 0.000 | \n",
    " | BaggingClassifier    | 0.938 +/- 0.013 | 0.793 +/- 0.022 | 0.859 +/- 0.016 | 0.965 +/- 0.004 | 0.951 +/- 0.005 | \n",
    " | DecisionTree         | 0.933 +/- 0.016 | 0.802 +/- 0.008 | 0.863 +/- 0.010 | 0.966 +/- 0.003 | 0.949 +/- 0.003 | \n",
    " | **GradientBoosting** | 0.971 +/- 0.008 | 0.743 +/- 0.026 | 0.842 +/- 0.019 | 0.963 +/- 0.004 | 0.927 +/- 0.005 | \n",
    " | KNeighbors           | 0.977 +/- 0.032 | 0.275 +/- 0.022 | 0.429 +/- 0.029 | 0.902 +/- 0.004 | 0.554 +/- 0.018 | \n",
    " | LogisticRegression   | 0.955 +/- 0.010 | 0.866 +/- 0.015 | 0.909 +/- 0.006 | 0.977 +/- 0.001 | 0.997 +/- 0.001 | \n",
    " | **RandomForest**     | 1.000 +/- 0.000 | 0.725 +/- 0.022 | 0.841 +/- 0.015 | 0.963 +/- 0.003 | 1.000 +/- 0.000 | \n",
    " | XGBClassifier        | 0.960 +/- 0.012 | 0.822 +/- 0.020 | 0.886 +/- 0.010 | 0.972 +/- 0.002 | 0.964 +/- 0.006 | \n",
    "\n",
    " | Model Args      | Precision | Recall | F1 Score | Accuracy | Train - F1 Score |\n",
    " | --------------- | :-------: | :----: | :------: | :------: | :--------------: |\n",
    " | RandomForestClassifier(n_estimators=250)                         | 1.000 | 0.754 | 0.860 | 0.967 | 1.000 | \n",
    " | **RandomForestClassifier(max_depth=100, n_estimators=250)**      | 1.000 | 0.706 | 0.828 | 0.961 | 0.984 | \n",
    " | RandomForestClassifier(max_depth=75, n_estimators=250)           | 1.000 | 0.706 | 0.828 | 0.961 | 0.948 | \n",
    " | RandomForestClassifier(max_depth=50, n_estimators=250)           | 1.000 | 0.647 | 0.786 | 0.953 | 0.889 | \n",
    " | RandomForestClassifier(max_depth=25, n_estimators=250)           | 1.000 | 0.374 | 0.545 | 0.916 | 0.675 | \n",
    " | RandomForestClassifier(max_depth=20, n_estimators=250)           | 1.000 | 0.299 | 0.461 | 0.906 | 0.566 | \n",
    " | RandomForestClassifier(max_depth=15, n_estimators=250)           | 1.000 | 0.166 | 0.284 | 0.888 | 0.341 |\n",
    "\n",
    " | Model Args      | Precision | Recall | F1 Score | Accuracy | Train - F1 Score |\n",
    " | --------------- | :-------: | :----: | :------: | :------: | :--------------: |\n",
    " | GradientBoostingClassifier(max_depth=50, n_estimators=250)       | 0.938 | 0.807 | 0.868 | 0.967 | 1.000 | \n",
    " | GradientBoostingClassifier(max_depth=25, n_estimators=250)       | 0.940 | 0.834 | 0.884 | 0.971 | 1.000 | \n",
    " | GradientBoostingClassifier(max_depth=20, n_estimators=250)       | 0.940 | 0.840 | 0.887 | 0.971 | 1.000 | \n",
    " | **GradientBoostingClassifier(max_depth=15, n_estimators=250)**   | 0.940 | 0.840 | 0.887 | 0.971 | 1.000 | \n",
    " | GradientBoostingClassifier(max_depth=10, n_estimators=250)       | 0.951 | 0.834 | 0.889 | 0.972 | 1.000 | \n",
    "\n",
    "- I performed a final model stability test on our baseline and leading models. Random Forest recall performance was still middling. I returned to vectorization parameters and found that turning off n_grams significantly improved recall on random forest - by ~4-sigma.\n",
    "- In its final form, random forest is performing with a precision score of 0.996 - just one false postive for every 249 true positives - while recall performance is also meeting goal with 82.4% of spam messages being flagged. While some spam messages will go through, this can be somewhat mitigated by UI design.\n",
    "- The finding that the original text outperforms cleaned text shows that there is still work to be done in cleaning the text, especially since when the corpus is so messy with abbreviations and typos.\n",
    "\n",
    " | Vectorize | Model    | Args           | Precision | Recall | F1 Score | Accuracy | Train - F1 Score |\n",
    " | --------- | -------- | -------------- | :-------: | :----: | :------: | :------: | :--------------: |\n",
    " | n_grams = 3 | DecisionTree | max_depth=20 | 0.920 +/- 0.018 | 0.811 +/- 0.020 | 0.862 +/- 0.013 | 0.965 +/- 0.003 | 0.949 +/- 0.004 | \n",
    " | n_grams = 3 | GradientBoosting | max_depth=20 | 0.950 +/- 0.010 | 0.842 +/- 0.020 | 0.893 +/- 0.009 | 0.973 +/- 0.002 | 1.000 +/- 0.000 | \n",
    " | n_grams = 3 | LogisticRegression | C=0.5, 'balanced' | 0.952 +/- 0.015 | 0.879 +/- 0.013 | 0.914 +/- 0.010 | 0.978 +/- 0.003 | 0.997 +/- 0.001 | \n",
    " | n_grams = 3 | **RandomForest** | **max_depth=100** | 0.999 +/- 0.005 | 0.740 +/- 0.025 | 0.850 +/- 0.018 | 0.965 +/- 0.004 | 0.983 +/- 0.003 | \n",
    " | n_grams = 1 | DecisionTree | max_depth=20 | 0.929 +/- 0.026 | 0.819 +/- 0.025 | 0.870 +/- 0.017 | 0.967 +/- 0.004 | 0.944 +/- 0.004 | \n",
    " | n_grams = 1 | GradientBoosting | max_depth=20 | 0.972 +/- 0.012 | 0.852 +/- 0.027 | 0.908 +/- 0.015 | 0.977 +/- 0.004 | 1.000 +/- 0.000 | \n",
    " | n_grams = 1 | LogisticRegression | C=0.5, 'balanced' | 0.944 +/- 0.019 | 0.901 +/- 0.019 | 0.921 +/- 0.016 | 0.979 +/- 0.004 | 0.990 +/- 0.002 | \n",
    " | n_grams = 1 | **RandomForest** | **max_depth=100** | 0.996 +/- 0.005 | 0.824 +/- 0.026 | 0.902 +/- 0.016 | 0.976 +/- 0.004 | 0.996 +/- 0.001 | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d760093-0926-46e6-9db6-1bd7d6958ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ade9baec-67ef-40df-9556-85c31e4be59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_stats_header():\n",
    "    print('\\n| Stats: Model                                                      | Prec  | Recal | TstF1 | Accu  | TrnF1 |')\n",
    "    print('-------------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "def print_test_stats(strategy, y_test, test_pred, y_train, train_pred):\n",
    "    num_space = 64 - (len(str(strategy)) % 64)\n",
    "    print('', str(strategy) + ' ' * num_space,\n",
    "          f'{precision_score(y_test, test_pred):.3f}',\n",
    "          f'{recall_score(y_test, test_pred):.3f}',\n",
    "          f'{f1_score(y_test, test_pred):.3f}',\n",
    "          f'{accuracy_score(y_test, test_pred):.3f}',\n",
    "          f'{f1_score(y_train, train_pred):.3f}',\n",
    "    '', sep=' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc71b56a-4fdf-4e68-89b4-9150f696ed41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Vectorization Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50f8f0ad-288d-4c07-9e79-72a07879b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=20)\n",
      "\t\t\tPrecision (mean +/- stdev): 0.934 +/- 0.017\n",
      "LogisticRegression(C=0.5, class_weight='balanced')\n",
      "\t\t\tPrecision (mean +/- stdev): 0.945 +/- 0.033\n"
     ]
    }
   ],
   "source": [
    "# column selection\n",
    "numerical_columns = ['org_length']\n",
    "text_column = 'text_cln'\n",
    "\n",
    "# process numeric columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# vectorize test flow\n",
    "vectorize_transformer_test = Pipeline(steps=[\n",
    "    (\"vectorizer_test\", CountVectorizer(ngram_range=(1, 3), stop_words='english')),\n",
    "])\n",
    "\n",
    "# preprocess test flow\n",
    "preprocess_test = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_transformer, numerical_columns),\n",
    "        ('vectorizer_test', vectorize_transformer_test, text_column)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# models to test\n",
    "models = {\n",
    "    'dt': DecisionTreeClassifier(max_depth=20),\n",
    "    'lr': LogisticRegression(class_weight='balanced', C=0.5)\n",
    "}\n",
    "\n",
    "# run test flow\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='target'),\n",
    "                                                    df['target'],\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=df['target']\n",
    "                                                   )\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe_test = Pipeline(steps=[\n",
    "        ('preprocessor_test', preprocess_test),\n",
    "        ('model', model)\n",
    "    ])    \n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    model_precision = cross_val_score(estimator=pipe_test,\n",
    "                            X=X_train,\n",
    "                            y=y_train,\n",
    "                            scoring='precision',\n",
    "                            cv=cv\n",
    "                            )\n",
    "    print(f'{model}\\n\\t\\t\\tPrecision (mean +/- stdev): {model_precision.mean():.3f} +/- {model_precision.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6717e06-d244-4e81-9126-ea53dc384060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   |   |   |--- free <= 0.50\n",
      "|   |   |   |--- free >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- il free today <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- il free today >  0.50\n",
      "|   |   |--- txt <= 0.50\n",
      "|   |   |--- txt >  0.50\n",
      "|   |--- txt <= 0.50\n",
      "|   |--- txt >  0.50\n",
      "|   |   |   |   |   |   |   |--- urgent message waiting <= 0.50\n",
      "|   |   |   |   |   |   |   |--- urgent message waiting >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- mobile <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- mobile >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- just text <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- just text >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |--- text <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |--- text >  0.50\n",
      "|   |   |   |   |   |   |--- claim <= 0.50\n",
      "|   |   |   |   |   |   |--- claim >  0.50\n",
      "|   |   |--- claim <= 0.50\n",
      "|   |   |--- claim >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |--- reply <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |--- reply >  0.50\n",
      "|   |   |   |   |--- www <= 0.50\n",
      "|   |   |   |   |--- www >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- just text <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |--- just text >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |--- just <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |--- just >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |--- ve won <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |   |--- ve won >  0.50\n",
      "|   |--- uk <= 0.50\n",
      "|   |--- uk >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |--- uk <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |   |--- uk >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |--- ll send <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |--- ll send >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- 150p <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |--- 150p >  0.50\n",
      "|   |   |   |   |   |   |--- 150ppm <= 0.50\n",
      "|   |   |   |   |   |   |   |--- 150p <= 0.50\n",
      "|   |   |   |   |   |   |   |--- 150p >  0.50\n",
      "|   |   |   |   |   |   |--- 150ppm >  0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |--- new message <= 0.50\n",
      "|   |   |   |   |   |   |   |   |   |   |   |   |--- new message >  0.50\n",
      "|   |   |   |   |   |   |   |--- urgent message waiting <= 0.50\n",
      "|   |   |   |   |   |   |   |--- urgent message waiting >  0.50\n"
     ]
    }
   ],
   "source": [
    "tree_text = str(export_text(dtc,\n",
    "                            feature_names=preprocess.get_feature_names_out(),\n",
    "                            class_names=['ham', 'spam'],\n",
    "                            max_depth=9999)\n",
    "                .replace('vectorize__', '')).split('\\n')\n",
    "\n",
    "for spam_word in spam_top_words.head(20)['word'].to_list():\n",
    "    for node in tree_text:\n",
    "        if spam_word in node:\n",
    "            print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18982009-3752-4102-8884-b47363556b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numeric__org_length</td>\n",
       "      <td>0.304847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txt</td>\n",
       "      <td>0.098576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claim</td>\n",
       "      <td>0.068925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>free</td>\n",
       "      <td>0.050703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>service</td>\n",
       "      <td>0.049876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>www</td>\n",
       "      <td>0.042876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uk</td>\n",
       "      <td>0.037149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150p</td>\n",
       "      <td>0.029804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150ppm</td>\n",
       "      <td>0.026947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>collection</td>\n",
       "      <td>0.018590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mobile</td>\n",
       "      <td>0.017810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>private</td>\n",
       "      <td>0.017657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>min</td>\n",
       "      <td>0.015567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ringtone</td>\n",
       "      <td>0.015424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reply</td>\n",
       "      <td>0.014756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rate</td>\n",
       "      <td>0.013276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>customer</td>\n",
       "      <td>0.009573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>awarded</td>\n",
       "      <td>0.008930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>urgent message waiting</td>\n",
       "      <td>0.008908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chat</td>\n",
       "      <td>0.008008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "0      numeric__org_length    0.304847\n",
       "1                      txt    0.098576\n",
       "2                    claim    0.068925\n",
       "3                     free    0.050703\n",
       "4                  service    0.049876\n",
       "5                      www    0.042876\n",
       "6                       uk    0.037149\n",
       "7                     150p    0.029804\n",
       "8                   150ppm    0.026947\n",
       "9               collection    0.018590\n",
       "10                  mobile    0.017810\n",
       "11                 private    0.017657\n",
       "12                     min    0.015567\n",
       "13                ringtone    0.015424\n",
       "14                   reply    0.014756\n",
       "15                    rate    0.013276\n",
       "16                customer    0.009573\n",
       "17                 awarded    0.008930\n",
       "18  urgent message waiting    0.008908\n",
       "19                    chat    0.008008"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_features = pd.DataFrame(dtc.feature_importances_,\n",
    "             index=preprocess.get_feature_names_out()\n",
    "            ).sort_values(0, ascending=False).reset_index()\n",
    "dtc_features.columns = ['feature', 'importance']\n",
    "dtc_features['feature'] = dtc_features['feature'].str.replace('vectorize__', '')\n",
    "dtc_features.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf000bba-5b93-486f-94ff-c17bbe0d1eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new</td>\n",
       "      <td>[1.773548707474209]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txt</td>\n",
       "      <td>[1.684834822194616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freephone</td>\n",
       "      <td>[1.6460548942194542]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146tf150p</td>\n",
       "      <td>[1.5567566895515934]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>message</td>\n",
       "      <td>[1.5251640649143252]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uk</td>\n",
       "      <td>[1.512432287331857]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claim</td>\n",
       "      <td>[1.4529662918847792]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>service</td>\n",
       "      <td>[1.3600981979039983]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>free</td>\n",
       "      <td>[1.3368203439471549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lost</td>\n",
       "      <td>[1.2660449691556603]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>www</td>\n",
       "      <td>[1.2431132946542973]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>won</td>\n",
       "      <td>[1.2389031340769299]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150p</td>\n",
       "      <td>[1.228937833032869]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>new message</td>\n",
       "      <td>[1.219671618682138]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reply</td>\n",
       "      <td>[1.1795608676383804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>help</td>\n",
       "      <td>[1.1621164874451593]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>text</td>\n",
       "      <td>[1.1486896578855919]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>prize</td>\n",
       "      <td>[1.0871174550814349]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mobile</td>\n",
       "      <td>[1.0716690631943695]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ringtone</td>\n",
       "      <td>[1.059921403921141]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features                 coeff\n",
       "0           new   [1.773548707474209]\n",
       "1           txt   [1.684834822194616]\n",
       "2     freephone  [1.6460548942194542]\n",
       "3     146tf150p  [1.5567566895515934]\n",
       "4       message  [1.5251640649143252]\n",
       "5            uk   [1.512432287331857]\n",
       "6         claim  [1.4529662918847792]\n",
       "7       service  [1.3600981979039983]\n",
       "8          free  [1.3368203439471549]\n",
       "9          lost  [1.2660449691556603]\n",
       "10          www  [1.2431132946542973]\n",
       "11          won  [1.2389031340769299]\n",
       "12         150p   [1.228937833032869]\n",
       "13  new message   [1.219671618682138]\n",
       "14        reply  [1.1795608676383804]\n",
       "15         help  [1.1621164874451593]\n",
       "16         text  [1.1486896578855919]\n",
       "17        prize  [1.0871174550814349]\n",
       "18       mobile  [1.0716690631943695]\n",
       "19     ringtone   [1.059921403921141]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(zip(preprocess.get_feature_names_out(), np.transpose(lr.coef_)), columns=['features', 'coeff'])\n",
    "coeff_df['features'] = coeff_df['features'].str.replace('vectorize__', '')\n",
    "coeff_df['abs_coeff'] = abs(coeff_df['coeff'])\n",
    "coeff_df = coeff_df.sort_values('abs_coeff', ascending=False).reset_index()\n",
    "coeff_df[['features', 'coeff']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c819158c-567a-48f0-b700-558ceb28bb89",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fa72ff6-1edd-4b8b-b51a-4071fdc1a3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Stats: Model                                                      | Prec  | Recal | TstF1 | Accu  | TrnF1 |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      " | DecisionTreeClassifier(max_depth=20)                             | 0.939 | 0.829 | 0.881 | 0.970 | 0.945 | \n",
      " | LogisticRegression(C=0.5, class_weight='balanced')               | 0.956 | 0.930 | 0.943 | 0.985 | 0.996 | \n",
      " | KNeighborsClassifier()                                           | 0.981 | 0.283 | 0.440 | 0.903 | 0.526 | \n",
      " | BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=20))                                                                | 0.962 | 0.807 | 0.878 | 0.970 | 0.940 | \n",
      " | RandomForestClassifier()                                         | 1.000 | 0.749 | 0.856 | 0.966 | 1.000 | \n",
      " | AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=20))                                                               | 0.988 | 0.882 | 0.932 | 0.983 | 1.000 | \n",
      " | GradientBoostingClassifier(max_depth=20, n_estimators=250)       | 0.964 | 0.861 | 0.910 | 0.977 | 1.000 | \n",
      " | XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              feature_weights=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, ...)         | 0.982 | 0.893 | 0.936 | 0.983 | 0.958 | \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7913d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7913d_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Precision</th>\n",
       "      <th id=\"T_7913d_level0_col2\" class=\"col_heading level0 col2\" colspan=\"2\">Recall</th>\n",
       "      <th id=\"T_7913d_level0_col4\" class=\"col_heading level0 col4\" colspan=\"2\">F1_Test</th>\n",
       "      <th id=\"T_7913d_level0_col6\" class=\"col_heading level0 col6\" colspan=\"2\">Accuracy</th>\n",
       "      <th id=\"T_7913d_level0_col8\" class=\"col_heading level0 col8\" colspan=\"2\">F1_Train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_7913d_level1_col0\" class=\"col_heading level1 col0\" >mean</th>\n",
       "      <th id=\"T_7913d_level1_col1\" class=\"col_heading level1 col1\" >std</th>\n",
       "      <th id=\"T_7913d_level1_col2\" class=\"col_heading level1 col2\" >mean</th>\n",
       "      <th id=\"T_7913d_level1_col3\" class=\"col_heading level1 col3\" >std</th>\n",
       "      <th id=\"T_7913d_level1_col4\" class=\"col_heading level1 col4\" >mean</th>\n",
       "      <th id=\"T_7913d_level1_col5\" class=\"col_heading level1 col5\" >std</th>\n",
       "      <th id=\"T_7913d_level1_col6\" class=\"col_heading level1 col6\" >mean</th>\n",
       "      <th id=\"T_7913d_level1_col7\" class=\"col_heading level1 col7\" >std</th>\n",
       "      <th id=\"T_7913d_level1_col8\" class=\"col_heading level1 col8\" >mean</th>\n",
       "      <th id=\"T_7913d_level1_col9\" class=\"col_heading level1 col9\" >std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7913d_level0_row0\" class=\"row_heading level0 row0\" >AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=20))</th>\n",
       "      <td id=\"T_7913d_row0_col0\" class=\"data row0 col0\" >0.966</td>\n",
       "      <td id=\"T_7913d_row0_col1\" class=\"data row0 col1\" >0.015</td>\n",
       "      <td id=\"T_7913d_row0_col2\" class=\"data row0 col2\" >0.867</td>\n",
       "      <td id=\"T_7913d_row0_col3\" class=\"data row0 col3\" >0.028</td>\n",
       "      <td id=\"T_7913d_row0_col4\" class=\"data row0 col4\" >0.914</td>\n",
       "      <td id=\"T_7913d_row0_col5\" class=\"data row0 col5\" >0.018</td>\n",
       "      <td id=\"T_7913d_row0_col6\" class=\"data row0 col6\" >0.978</td>\n",
       "      <td id=\"T_7913d_row0_col7\" class=\"data row0 col7\" >0.004</td>\n",
       "      <td id=\"T_7913d_row0_col8\" class=\"data row0 col8\" >1.000</td>\n",
       "      <td id=\"T_7913d_row0_col9\" class=\"data row0 col9\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7913d_level0_row1\" class=\"row_heading level0 row1\" >BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=20))</th>\n",
       "      <td id=\"T_7913d_row1_col0\" class=\"data row1 col0\" >0.952</td>\n",
       "      <td id=\"T_7913d_row1_col1\" class=\"data row1 col1\" >0.019</td>\n",
       "      <td id=\"T_7913d_row1_col2\" class=\"data row1 col2\" >0.821</td>\n",
       "      <td id=\"T_7913d_row1_col3\" class=\"data row1 col3\" >0.026</td>\n",
       "      <td id=\"T_7913d_row1_col4\" class=\"data row1 col4\" >0.882</td>\n",
       "      <td id=\"T_7913d_row1_col5\" class=\"data row1 col5\" >0.021</td>\n",
       "      <td id=\"T_7913d_row1_col6\" class=\"data row1 col6\" >0.970</td>\n",
       "      <td id=\"T_7913d_row1_col7\" class=\"data row1 col7\" >0.005</td>\n",
       "      <td id=\"T_7913d_row1_col8\" class=\"data row1 col8\" >0.943</td>\n",
       "      <td id=\"T_7913d_row1_col9\" class=\"data row1 col9\" >0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7913d_level0_row2\" class=\"row_heading level0 row2\" >DecisionTreeClassifier(max_depth=20)</th>\n",
       "      <td id=\"T_7913d_row2_col0\" class=\"data row2 col0\" >0.947</td>\n",
       "      <td id=\"T_7913d_row2_col1\" class=\"data row2 col1\" >0.024</td>\n",
       "      <td id=\"T_7913d_row2_col2\" class=\"data row2 col2\" >0.829</td>\n",
       "      <td id=\"T_7913d_row2_col3\" class=\"data row2 col3\" >0.010</td>\n",
       "      <td id=\"T_7913d_row2_col4\" class=\"data row2 col4\" >0.884</td>\n",
       "      <td id=\"T_7913d_row2_col5\" class=\"data row2 col5\" >0.016</td>\n",
       "      <td id=\"T_7913d_row2_col6\" class=\"data row2 col6\" >0.971</td>\n",
       "      <td id=\"T_7913d_row2_col7\" class=\"data row2 col7\" >0.004</td>\n",
       "      <td id=\"T_7913d_row2_col8\" class=\"data row2 col8\" >0.948</td>\n",
       "      <td id=\"T_7913d_row2_col9\" class=\"data row2 col9\" >0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7913d_level0_row3\" class=\"row_heading level0 row3\" >GradientBoostingClassifier(max_depth=20, n_estimators=250)</th>\n",
       "      <td id=\"T_7913d_row3_col0\" class=\"data row3 col0\" >0.968</td>\n",
       "      <td id=\"T_7913d_row3_col1\" class=\"data row3 col1\" >0.012</td>\n",
       "      <td id=\"T_7913d_row3_col2\" class=\"data row3 col2\" >0.849</td>\n",
       "      <td id=\"T_7913d_row3_col3\" class=\"data row3 col3\" >0.026</td>\n",
       "      <td id=\"T_7913d_row3_col4\" class=\"data row3 col4\" >0.905</td>\n",
       "      <td id=\"T_7913d_row3_col5\" class=\"data row3 col5\" >0.019</td>\n",
       "      <td id=\"T_7913d_row3_col6\" class=\"data row3 col6\" >0.976</td>\n",
       "      <td id=\"T_7913d_row3_col7\" class=\"data row3 col7\" >0.005</td>\n",
       "      <td id=\"T_7913d_row3_col8\" class=\"data row3 col8\" >1.000</td>\n",
       "      <td id=\"T_7913d_row3_col9\" class=\"data row3 col9\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7913d_level0_row4\" class=\"row_heading level0 row4\" >KNeighborsClassifier()</th>\n",
       "      <td id=\"T_7913d_row4_col0\" class=\"data row4 col0\" >0.985</td>\n",
       "      <td id=\"T_7913d_row4_col1\" class=\"data row4 col1\" >0.017</td>\n",
       "      <td id=\"T_7913d_row4_col2\" class=\"data row4 col2\" >0.290</td>\n",
       "      <td id=\"T_7913d_row4_col3\" class=\"data row4 col3\" >0.035</td>\n",
       "      <td id=\"T_7913d_row4_col4\" class=\"data row4 col4\" >0.447</td>\n",
       "      <td id=\"T_7913d_row4_col5\" class=\"data row4 col5\" >0.042</td>\n",
       "      <td id=\"T_7913d_row4_col6\" class=\"data row4 col6\" >0.904</td>\n",
       "      <td id=\"T_7913d_row4_col7\" class=\"data row4 col7\" >0.005</td>\n",
       "      <td id=\"T_7913d_row4_col8\" class=\"data row4 col8\" >0.553</td>\n",
       "      <td id=\"T_7913d_row4_col9\" class=\"data row4 col9\" >0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7913d_level0_row5\" class=\"row_heading level0 row5\" >LogisticRegression(C=0.5, class_weight='balanced')</th>\n",
       "      <td id=\"T_7913d_row5_col0\" class=\"data row5 col0\" >0.955</td>\n",
       "      <td id=\"T_7913d_row5_col1\" class=\"data row5 col1\" >0.004</td>\n",
       "      <td id=\"T_7913d_row5_col2\" class=\"data row5 col2\" >0.889</td>\n",
       "      <td id=\"T_7913d_row5_col3\" class=\"data row5 col3\" >0.027</td>\n",
       "      <td id=\"T_7913d_row5_col4\" class=\"data row5 col4\" >0.921</td>\n",
       "      <td id=\"T_7913d_row5_col5\" class=\"data row5 col5\" >0.014</td>\n",
       "      <td id=\"T_7913d_row5_col6\" class=\"data row5 col6\" >0.979</td>\n",
       "      <td id=\"T_7913d_row5_col7\" class=\"data row5 col7\" >0.003</td>\n",
       "      <td id=\"T_7913d_row5_col8\" class=\"data row5 col8\" >0.997</td>\n",
       "      <td id=\"T_7913d_row5_col9\" class=\"data row5 col9\" >0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7913d_level0_row6\" class=\"row_heading level0 row6\" >RandomForestClassifier()</th>\n",
       "      <td id=\"T_7913d_row6_col0\" class=\"data row6 col0\" >1.000</td>\n",
       "      <td id=\"T_7913d_row6_col1\" class=\"data row6 col1\" >0.000</td>\n",
       "      <td id=\"T_7913d_row6_col2\" class=\"data row6 col2\" >0.758</td>\n",
       "      <td id=\"T_7913d_row6_col3\" class=\"data row6 col3\" >0.019</td>\n",
       "      <td id=\"T_7913d_row6_col4\" class=\"data row6 col4\" >0.862</td>\n",
       "      <td id=\"T_7913d_row6_col5\" class=\"data row6 col5\" >0.012</td>\n",
       "      <td id=\"T_7913d_row6_col6\" class=\"data row6 col6\" >0.968</td>\n",
       "      <td id=\"T_7913d_row6_col7\" class=\"data row6 col7\" >0.003</td>\n",
       "      <td id=\"T_7913d_row6_col8\" class=\"data row6 col8\" >1.000</td>\n",
       "      <td id=\"T_7913d_row6_col9\" class=\"data row6 col9\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7913d_level0_row7\" class=\"row_heading level0 row7\" >XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</th>\n",
       "      <td id=\"T_7913d_row7_col0\" class=\"data row7 col0\" >0.966</td>\n",
       "      <td id=\"T_7913d_row7_col1\" class=\"data row7 col1\" >0.015</td>\n",
       "      <td id=\"T_7913d_row7_col2\" class=\"data row7 col2\" >0.851</td>\n",
       "      <td id=\"T_7913d_row7_col3\" class=\"data row7 col3\" >0.035</td>\n",
       "      <td id=\"T_7913d_row7_col4\" class=\"data row7 col4\" >0.905</td>\n",
       "      <td id=\"T_7913d_row7_col5\" class=\"data row7 col5\" >0.024</td>\n",
       "      <td id=\"T_7913d_row7_col6\" class=\"data row7 col6\" >0.976</td>\n",
       "      <td id=\"T_7913d_row7_col7\" class=\"data row7 col7\" >0.006</td>\n",
       "      <td id=\"T_7913d_row7_col8\" class=\"data row7 col8\" >0.962</td>\n",
       "      <td id=\"T_7913d_row7_col9\" class=\"data row7 col9\" >0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x32504b5d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models to test\n",
    "models = {\n",
    "    'dt': DecisionTreeClassifier(max_depth=20),\n",
    "    'lr': LogisticRegression(class_weight='balanced', C=0.5),\n",
    "    'knn ': KNeighborsClassifier(),\n",
    "    'bag ': BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=20)),\n",
    "    'rf  ': RandomForestClassifier(),\n",
    "    'ada ': AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=20)),\n",
    "    'grad': GradientBoostingClassifier(n_estimators=250, max_depth=20),\n",
    "    'xgb ': xgb.XGBClassifier(verbosity=1)\n",
    "}\n",
    "\n",
    "results_list = []\n",
    "\n",
    "print_test_stats_header()\n",
    "\n",
    "for i in range(5):\n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='target'),\n",
    "                                                                df['target'],\n",
    "                                                                test_size=0.25,\n",
    "                                                                stratify=df['target']\n",
    "                                                               )\n",
    "    for name, model in models.items():\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', preprocess),\n",
    "            ('model', model)\n",
    "        ])    \n",
    "\n",
    "        # Run Pipeline\n",
    "        pipe.fit(X_train, y_train)\n",
    "        test_pred = pipe.predict(X_test)\n",
    "        train_pred = pipe.predict(X_train)\n",
    "    \n",
    "        # Stats\n",
    "        print_test_stats(pipe[1], y_test, test_pred, y_train, train_pred) if i==0 else ''\n",
    "\n",
    "        results_list.append([str(pipe[1]),\n",
    "                             precision_score(y_test, test_pred),\n",
    "                             recall_score(y_test, test_pred),\n",
    "                             f1_score(y_test, test_pred),\n",
    "                             accuracy_score(y_test, test_pred),\n",
    "                             f1_score(y_train, train_pred)\n",
    "                        ])\n",
    "\n",
    "result_df = pd.DataFrame(results_list, columns=['Model', 'Precision', 'Recall', 'F1_Test', 'Accuracy', 'F1_Train'])\n",
    "\n",
    "result_df.groupby('Model').agg(['mean', 'std']).style.format(precision=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3380d04-eb5a-4301-a18c-d9b881ec3c35",
   "metadata": {},
   "source": [
    "## Selected Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fb30e06-a228-4a6e-a6f6-591e9d98d2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Stats: Model                                                      | Prec  | Recal | TstF1 | Accu  | TrnF1 |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      " | RandomForestClassifier(n_estimators=250)                         | 1.000 | 0.791 | 0.884 | 0.972 | 1.000 | \n",
      " | RandomForestClassifier(max_depth=100, n_estimators=250)          | 1.000 | 0.791 | 0.884 | 0.972 | 0.996 | \n",
      " | RandomForestClassifier(max_depth=75, n_estimators=250)           | 1.000 | 0.791 | 0.884 | 0.972 | 0.986 | \n",
      " | RandomForestClassifier(max_depth=50, n_estimators=250)           | 1.000 | 0.759 | 0.863 | 0.968 | 0.961 | \n",
      " | RandomForestClassifier(max_depth=25, n_estimators=250)           | 1.000 | 0.647 | 0.786 | 0.953 | 0.871 | \n",
      " | RandomForestClassifier(max_depth=20, n_estimators=250)           | 1.000 | 0.599 | 0.749 | 0.946 | 0.822 | \n",
      " | RandomForestClassifier(max_depth=15, n_estimators=250)           | 1.000 | 0.519 | 0.683 | 0.935 | 0.719 | \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      1206\n",
      "           1       1.00      0.52      0.68       187\n",
      "\n",
      "    accuracy                           0.94      1393\n",
      "   macro avg       0.97      0.76      0.82      1393\n",
      "weighted avg       0.94      0.94      0.93      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run decision tree pipeline\n",
    "\n",
    "print_test_stats_header()\n",
    "\n",
    "for i in [None, 100, 75, 50, 25, 20, 15]:\n",
    "    rf = RandomForestClassifier(max_depth=i, n_estimators=250)\n",
    "    \n",
    "    pipe_rf = Pipeline(steps=[\n",
    "        ('preprocessor', preprocess),\n",
    "        ('random_forest_classifier', rf)\n",
    "    ])\n",
    "    \n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='target'),\n",
    "                                                        df['target'],\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=df['target']\n",
    "                                                       )\n",
    "    \n",
    "    # Run Pipeline\n",
    "    pipe_rf.fit(X_train, y_train)\n",
    "    test_pred = pipe_rf.predict(X_test)\n",
    "    train_pred = pipe_rf.predict(X_train)\n",
    "    \n",
    "    # Stats\n",
    "    print_test_stats(pipe_rf[1], y_test, test_pred, y_train, train_pred)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c890a37-155d-4627-8390-32344046a4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Stats: Model                                                      | Prec  | Recal | TstF1 | Accu  | TrnF1 |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      " | GradientBoostingClassifier(max_depth=50, n_estimators=250)       | 0.938 | 0.807 | 0.868 | 0.967 | 1.000 | \n",
      " | GradientBoostingClassifier(max_depth=25, n_estimators=250)       | 0.940 | 0.845 | 0.890 | 0.972 | 1.000 | \n",
      " | GradientBoostingClassifier(max_depth=20, n_estimators=250)       | 0.940 | 0.845 | 0.890 | 0.972 | 1.000 | \n",
      " | GradientBoostingClassifier(max_depth=15, n_estimators=250)       | 0.946 | 0.840 | 0.890 | 0.972 | 1.000 | \n",
      " | GradientBoostingClassifier(max_depth=10, n_estimators=250)       | 0.952 | 0.845 | 0.895 | 0.973 | 1.000 | \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1206\n",
      "           1       0.95      0.84      0.90       187\n",
      "\n",
      "    accuracy                           0.97      1393\n",
      "   macro avg       0.96      0.92      0.94      1393\n",
      "weighted avg       0.97      0.97      0.97      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run decision tree pipeline\n",
    "\n",
    "print_test_stats_header()\n",
    "\n",
    "for i in [50, 25, 20, 15, 10]:\n",
    "    grad = GradientBoostingClassifier(max_depth=i, n_estimators=250)\n",
    "    \n",
    "    pipe_grad = Pipeline(steps=[\n",
    "        ('preprocessor', preprocess),\n",
    "        ('grad_boost_classifier', grad)\n",
    "    ])\n",
    "    \n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='target'),\n",
    "                                                        df['target'],\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=42,\n",
    "                                                        stratify=df['target']\n",
    "                                                       )\n",
    "    \n",
    "    # Run Pipeline\n",
    "    pipe_grad.fit(X_train, y_train)\n",
    "    test_pred = pipe_grad.predict(X_test)\n",
    "    train_pred = pipe_grad.predict(X_train)\n",
    "    \n",
    "    # Stats\n",
    "    print_test_stats(pipe_grad[1], y_test, test_pred, y_train, train_pred)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "441f3955-2498-4f46-9ba6-9f2e59cc8b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Stats: Model                                                      | Prec  | Recal | TstF1 | Accu  | TrnF1 |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      " | DecisionTreeClassifier(max_depth=20)                             | 0.899 | 0.861 | 0.880 | 0.968 | 0.939 | \n",
      " | LogisticRegression(C=0.5, class_weight='balanced')               | 0.930 | 0.930 | 0.930 | 0.981 | 0.992 | \n",
      " | RandomForestClassifier(max_depth=100, n_estimators=250)          | 1.000 | 0.845 | 0.916 | 0.979 | 0.996 | \n",
      " | GradientBoostingClassifier(max_depth=15, n_estimators=250)       | 0.943 | 0.877 | 0.909 | 0.976 | 1.000 | \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_fce10\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fce10_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Precision</th>\n",
       "      <th id=\"T_fce10_level0_col2\" class=\"col_heading level0 col2\" colspan=\"2\">Recall</th>\n",
       "      <th id=\"T_fce10_level0_col4\" class=\"col_heading level0 col4\" colspan=\"2\">F1_Test</th>\n",
       "      <th id=\"T_fce10_level0_col6\" class=\"col_heading level0 col6\" colspan=\"2\">Accuracy</th>\n",
       "      <th id=\"T_fce10_level0_col8\" class=\"col_heading level0 col8\" colspan=\"2\">F1_Train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_fce10_level1_col0\" class=\"col_heading level1 col0\" >mean</th>\n",
       "      <th id=\"T_fce10_level1_col1\" class=\"col_heading level1 col1\" >std</th>\n",
       "      <th id=\"T_fce10_level1_col2\" class=\"col_heading level1 col2\" >mean</th>\n",
       "      <th id=\"T_fce10_level1_col3\" class=\"col_heading level1 col3\" >std</th>\n",
       "      <th id=\"T_fce10_level1_col4\" class=\"col_heading level1 col4\" >mean</th>\n",
       "      <th id=\"T_fce10_level1_col5\" class=\"col_heading level1 col5\" >std</th>\n",
       "      <th id=\"T_fce10_level1_col6\" class=\"col_heading level1 col6\" >mean</th>\n",
       "      <th id=\"T_fce10_level1_col7\" class=\"col_heading level1 col7\" >std</th>\n",
       "      <th id=\"T_fce10_level1_col8\" class=\"col_heading level1 col8\" >mean</th>\n",
       "      <th id=\"T_fce10_level1_col9\" class=\"col_heading level1 col9\" >std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Model</th>\n",
       "      <th class=\"index_name level1\" >Vectorize</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fce10_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">DecisionTreeClassifier(max_depth=20)</th>\n",
       "      <th id=\"T_fce10_level1_row0\" class=\"row_heading level1 row0\" >CountVectorizer(ngram_range=(1, 3), stop_words='english')</th>\n",
       "      <td id=\"T_fce10_row0_col0\" class=\"data row0 col0\" >0.950</td>\n",
       "      <td id=\"T_fce10_row0_col1\" class=\"data row0 col1\" >0.007</td>\n",
       "      <td id=\"T_fce10_row0_col2\" class=\"data row0 col2\" >0.824</td>\n",
       "      <td id=\"T_fce10_row0_col3\" class=\"data row0 col3\" >0.033</td>\n",
       "      <td id=\"T_fce10_row0_col4\" class=\"data row0 col4\" >0.882</td>\n",
       "      <td id=\"T_fce10_row0_col5\" class=\"data row0 col5\" >0.019</td>\n",
       "      <td id=\"T_fce10_row0_col6\" class=\"data row0 col6\" >0.970</td>\n",
       "      <td id=\"T_fce10_row0_col7\" class=\"data row0 col7\" >0.004</td>\n",
       "      <td id=\"T_fce10_row0_col8\" class=\"data row0 col8\" >0.945</td>\n",
       "      <td id=\"T_fce10_row0_col9\" class=\"data row0 col9\" >0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fce10_level1_row1\" class=\"row_heading level1 row1\" >CountVectorizer(stop_words='english')</th>\n",
       "      <td id=\"T_fce10_row1_col0\" class=\"data row1 col0\" >0.931</td>\n",
       "      <td id=\"T_fce10_row1_col1\" class=\"data row1 col1\" >0.027</td>\n",
       "      <td id=\"T_fce10_row1_col2\" class=\"data row1 col2\" >0.815</td>\n",
       "      <td id=\"T_fce10_row1_col3\" class=\"data row1 col3\" >0.034</td>\n",
       "      <td id=\"T_fce10_row1_col4\" class=\"data row1 col4\" >0.869</td>\n",
       "      <td id=\"T_fce10_row1_col5\" class=\"data row1 col5\" >0.017</td>\n",
       "      <td id=\"T_fce10_row1_col6\" class=\"data row1 col6\" >0.967</td>\n",
       "      <td id=\"T_fce10_row1_col7\" class=\"data row1 col7\" >0.004</td>\n",
       "      <td id=\"T_fce10_row1_col8\" class=\"data row1 col8\" >0.944</td>\n",
       "      <td id=\"T_fce10_row1_col9\" class=\"data row1 col9\" >0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fce10_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">GradientBoostingClassifier(max_depth=15, n_estimators=250)</th>\n",
       "      <th id=\"T_fce10_level1_row2\" class=\"row_heading level1 row2\" >CountVectorizer(ngram_range=(1, 3), stop_words='english')</th>\n",
       "      <td id=\"T_fce10_row2_col0\" class=\"data row2 col0\" >0.970</td>\n",
       "      <td id=\"T_fce10_row2_col1\" class=\"data row2 col1\" >0.012</td>\n",
       "      <td id=\"T_fce10_row2_col2\" class=\"data row2 col2\" >0.853</td>\n",
       "      <td id=\"T_fce10_row2_col3\" class=\"data row2 col3\" >0.038</td>\n",
       "      <td id=\"T_fce10_row2_col4\" class=\"data row2 col4\" >0.908</td>\n",
       "      <td id=\"T_fce10_row2_col5\" class=\"data row2 col5\" >0.019</td>\n",
       "      <td id=\"T_fce10_row2_col6\" class=\"data row2 col6\" >0.977</td>\n",
       "      <td id=\"T_fce10_row2_col7\" class=\"data row2 col7\" >0.004</td>\n",
       "      <td id=\"T_fce10_row2_col8\" class=\"data row2 col8\" >1.000</td>\n",
       "      <td id=\"T_fce10_row2_col9\" class=\"data row2 col9\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fce10_level1_row3\" class=\"row_heading level1 row3\" >CountVectorizer(stop_words='english')</th>\n",
       "      <td id=\"T_fce10_row3_col0\" class=\"data row3 col0\" >0.965</td>\n",
       "      <td id=\"T_fce10_row3_col1\" class=\"data row3 col1\" >0.020</td>\n",
       "      <td id=\"T_fce10_row3_col2\" class=\"data row3 col2\" >0.866</td>\n",
       "      <td id=\"T_fce10_row3_col3\" class=\"data row3 col3\" >0.022</td>\n",
       "      <td id=\"T_fce10_row3_col4\" class=\"data row3 col4\" >0.913</td>\n",
       "      <td id=\"T_fce10_row3_col5\" class=\"data row3 col5\" >0.008</td>\n",
       "      <td id=\"T_fce10_row3_col6\" class=\"data row3 col6\" >0.978</td>\n",
       "      <td id=\"T_fce10_row3_col7\" class=\"data row3 col7\" >0.002</td>\n",
       "      <td id=\"T_fce10_row3_col8\" class=\"data row3 col8\" >1.000</td>\n",
       "      <td id=\"T_fce10_row3_col9\" class=\"data row3 col9\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fce10_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"2\">LogisticRegression(C=0.5, class_weight='balanced')</th>\n",
       "      <th id=\"T_fce10_level1_row4\" class=\"row_heading level1 row4\" >CountVectorizer(ngram_range=(1, 3), stop_words='english')</th>\n",
       "      <td id=\"T_fce10_row4_col0\" class=\"data row4 col0\" >0.946</td>\n",
       "      <td id=\"T_fce10_row4_col1\" class=\"data row4 col1\" >0.024</td>\n",
       "      <td id=\"T_fce10_row4_col2\" class=\"data row4 col2\" >0.886</td>\n",
       "      <td id=\"T_fce10_row4_col3\" class=\"data row4 col3\" >0.037</td>\n",
       "      <td id=\"T_fce10_row4_col4\" class=\"data row4 col4\" >0.914</td>\n",
       "      <td id=\"T_fce10_row4_col5\" class=\"data row4 col5\" >0.020</td>\n",
       "      <td id=\"T_fce10_row4_col6\" class=\"data row4 col6\" >0.978</td>\n",
       "      <td id=\"T_fce10_row4_col7\" class=\"data row4 col7\" >0.005</td>\n",
       "      <td id=\"T_fce10_row4_col8\" class=\"data row4 col8\" >0.998</td>\n",
       "      <td id=\"T_fce10_row4_col9\" class=\"data row4 col9\" >0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fce10_level1_row5\" class=\"row_heading level1 row5\" >CountVectorizer(stop_words='english')</th>\n",
       "      <td id=\"T_fce10_row5_col0\" class=\"data row5 col0\" >0.944</td>\n",
       "      <td id=\"T_fce10_row5_col1\" class=\"data row5 col1\" >0.010</td>\n",
       "      <td id=\"T_fce10_row5_col2\" class=\"data row5 col2\" >0.911</td>\n",
       "      <td id=\"T_fce10_row5_col3\" class=\"data row5 col3\" >0.024</td>\n",
       "      <td id=\"T_fce10_row5_col4\" class=\"data row5 col4\" >0.927</td>\n",
       "      <td id=\"T_fce10_row5_col5\" class=\"data row5 col5\" >0.009</td>\n",
       "      <td id=\"T_fce10_row5_col6\" class=\"data row5 col6\" >0.981</td>\n",
       "      <td id=\"T_fce10_row5_col7\" class=\"data row5 col7\" >0.002</td>\n",
       "      <td id=\"T_fce10_row5_col8\" class=\"data row5 col8\" >0.991</td>\n",
       "      <td id=\"T_fce10_row5_col9\" class=\"data row5 col9\" >0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fce10_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"2\">RandomForestClassifier(max_depth=100, n_estimators=250)</th>\n",
       "      <th id=\"T_fce10_level1_row6\" class=\"row_heading level1 row6\" >CountVectorizer(ngram_range=(1, 3), stop_words='english')</th>\n",
       "      <td id=\"T_fce10_row6_col0\" class=\"data row6 col0\" >1.000</td>\n",
       "      <td id=\"T_fce10_row6_col1\" class=\"data row6 col1\" >0.000</td>\n",
       "      <td id=\"T_fce10_row6_col2\" class=\"data row6 col2\" >0.752</td>\n",
       "      <td id=\"T_fce10_row6_col3\" class=\"data row6 col3\" >0.043</td>\n",
       "      <td id=\"T_fce10_row6_col4\" class=\"data row6 col4\" >0.858</td>\n",
       "      <td id=\"T_fce10_row6_col5\" class=\"data row6 col5\" >0.028</td>\n",
       "      <td id=\"T_fce10_row6_col6\" class=\"data row6 col6\" >0.967</td>\n",
       "      <td id=\"T_fce10_row6_col7\" class=\"data row6 col7\" >0.006</td>\n",
       "      <td id=\"T_fce10_row6_col8\" class=\"data row6 col8\" >0.983</td>\n",
       "      <td id=\"T_fce10_row6_col9\" class=\"data row6 col9\" >0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fce10_level1_row7\" class=\"row_heading level1 row7\" >CountVectorizer(stop_words='english')</th>\n",
       "      <td id=\"T_fce10_row7_col0\" class=\"data row7 col0\" >0.998</td>\n",
       "      <td id=\"T_fce10_row7_col1\" class=\"data row7 col1\" >0.003</td>\n",
       "      <td id=\"T_fce10_row7_col2\" class=\"data row7 col2\" >0.843</td>\n",
       "      <td id=\"T_fce10_row7_col3\" class=\"data row7 col3\" >0.022</td>\n",
       "      <td id=\"T_fce10_row7_col4\" class=\"data row7 col4\" >0.914</td>\n",
       "      <td id=\"T_fce10_row7_col5\" class=\"data row7 col5\" >0.012</td>\n",
       "      <td id=\"T_fce10_row7_col6\" class=\"data row7 col6\" >0.979</td>\n",
       "      <td id=\"T_fce10_row7_col7\" class=\"data row7 col7\" >0.003</td>\n",
       "      <td id=\"T_fce10_row7_col8\" class=\"data row7 col8\" >0.996</td>\n",
       "      <td id=\"T_fce10_row7_col9\" class=\"data row7 col9\" >0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x177deee90>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models to test\n",
    "models = {\n",
    "    'dt': DecisionTreeClassifier(max_depth=20),\n",
    "    'lr': LogisticRegression(class_weight='balanced', C=0.5),\n",
    "    'rf  ': RandomForestClassifier(max_depth=100, n_estimators=250),\n",
    "    'grad': GradientBoostingClassifier(max_depth=15, n_estimators=250)\n",
    "}\n",
    "\n",
    "#results_list = []\n",
    "\n",
    "print_test_stats_header()\n",
    "\n",
    "for i in range(5):\n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(columns='target'),\n",
    "                                                                df['target'],\n",
    "                                                                test_size=0.25,\n",
    "                                                                stratify=df['target']\n",
    "                                                               )\n",
    "    for name, model in models.items():\n",
    "        pipe = Pipeline(steps=[\n",
    "            ('preprocessor', preprocess),\n",
    "            ('model', model)\n",
    "        ])    \n",
    "\n",
    "        # Run Pipeline\n",
    "        pipe.fit(X_train, y_train)\n",
    "        test_pred = pipe.predict(X_test)\n",
    "        train_pred = pipe.predict(X_train)\n",
    "    \n",
    "        # Stats\n",
    "        print_test_stats(pipe[1], y_test, test_pred, y_train, train_pred) if i==0 else ''\n",
    "\n",
    "        results_list.append([str(pipe[1]),\n",
    "                             str(vectorize_transformer[0]),\n",
    "                             precision_score(y_test, test_pred),\n",
    "                             recall_score(y_test, test_pred),\n",
    "                             f1_score(y_test, test_pred),\n",
    "                             accuracy_score(y_test, test_pred),\n",
    "                             f1_score(y_train, train_pred)\n",
    "                        ])\n",
    "\n",
    "result_df = pd.DataFrame(results_list, columns=['Model', 'Vectorize', 'Precision', 'Recall', 'F1_Test', 'Accuracy', 'F1_Train'])\n",
    "\n",
    "result_df.groupby(['Model', 'Vectorize']).agg(['mean', 'std']).style.format(precision=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ce041-c58d-4be4-af80-a2510ea46055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2025.06-py3.11",
   "language": "python",
   "name": "conda-env-anaconda-2025.06-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
